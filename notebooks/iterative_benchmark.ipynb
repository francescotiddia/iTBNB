{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:22:39.397472Z",
     "start_time": "2025-12-01T09:22:35.367336Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from TbNB import TbNB  \n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing.nltk_pipeline import TextPreprocessor\n",
    "from utils.benchmarking import run_experiment, evaluate_model\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading\n",
    "\n",
    "We can easily load data by using the dataset package, which allows us to directly connect with HugginFace repository. The enelpol/booking_com_reviews contains 516k samples and two columns: one for positive comments and one for negative ones (which compound to one single review). Data is therefore united in a single column and then split in training and test sets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a60fb981b71d1477"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = load_dataset(\"enelpol/booking_com_reviews\", split=\"train\").to_pandas()\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_pos = pd.DataFrame({\"review_text\": train_df[\"Positive_Review\"], \"label\": 1})\n",
    "train_neg = pd.DataFrame({\"review_text\": train_df[\"Negative_Review\"], \"label\": 0})\n",
    "\n",
    "test_pos = pd.DataFrame({\"review_text\": test_df[\"Positive_Review\"], \"label\": 1})\n",
    "test_neg = pd.DataFrame({\"review_text\": test_df[\"Negative_Review\"], \"label\": 0})\n",
    "\n",
    "\n",
    "train_df = pd.concat([train_pos, train_neg], ignore_index=True)\n",
    "test_df = pd.concat([test_pos, test_neg], ignore_index=True)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "train_reviews = train_df[\"review_text\"].tolist()\n",
    "test_reviews = test_df[\"review_text\"].tolist()\n",
    "\n",
    "train_labels = train_df[\"label\"].tolist()\n",
    "test_labels = test_df[\"label\"].tolist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:22:43.305993Z",
     "start_time": "2025-12-01T09:22:39.400427Z"
    }
   },
   "id": "7dac29244f817cb0",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Using the custom-built TextPreprocessor class allows for straightforward and quick data preprocessing. NLP data cleaning operations include: lowercasing, stopwords and punctuation removal, emoji conversion and stemming. Removing superfluous operations might speed up the process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d196d4d5ec79e5f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor(remove_html=False, remove_urls=False)\n",
    "preprocessor.fit(X = train_reviews)\n",
    "train_reviews = preprocessor.transform(train_reviews)\n",
    "test_reviews = preprocessor.transform(test_reviews)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:23:58.505419Z",
     "start_time": "2025-12-01T09:22:43.310301Z"
    }
   },
   "id": "3e8c9aaf5ad7aec1",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Vectorization\n",
    "\n",
    "Sklearn-like models only accept already vectorized data, therefore we employ sklearn.CountVectorizer to transform textual data into a BoW matrix. We also consider both single words and n-grams of length 2 to further capture the context within a sentence"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c712c4cf5126f3b7"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9054f92a1373ec98"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Iterative  Accuracy  F1-score  Train Time (s)  Predict Time (s)  Iterations\n",
      "0      False  0.929994  0.932033        2.305375          0.034455           0\n",
      "1       True  0.935607  0.936392        5.731552          0.058477           6\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    binary=False,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(train_reviews)\n",
    "X_test_vec  = vectorizer.transform(test_reviews)\n",
    "\n",
    "results_it = []\n",
    "res_false = run_experiment(False, X_train_vec, train_labels, X_test_vec, test_labels)\n",
    "res_true  = run_experiment(True, X_train_vec, train_labels, X_test_vec, test_labels)\n",
    "\n",
    "print(pd.DataFrame([res_false, res_true]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:24:23.755576Z",
     "start_time": "2025-12-01T09:23:58.508855Z"
    }
   },
   "id": "759aaad7cf8ce17d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model  Accuracy  F1-score  Train Time (s)  Predict Time (s)\n",
      "0  TbNB (non-iterative)  0.929994  0.932033        2.682678          0.036560\n",
      "1      TbNB (iterative)  0.935607  0.936392        4.210131          0.339915\n",
      "2         MultinomialNB  0.936325  0.937131        0.606347          0.119346\n",
      "3           BernoulliNB  0.933067  0.932249        0.543643          0.163990\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "models = [\n",
    "    (\"TbNB (non-iterative)\", TbNB(iterative=False)),\n",
    "    (\"TbNB (iterative)\", TbNB(iterative=True)),\n",
    "    (\"MultinomialNB\", MultinomialNB()),\n",
    "    (\"BernoulliNB\", BernoulliNB())]\n",
    "\n",
    "for name, model in models:\n",
    "    results.append(\n",
    "        evaluate_model(\n",
    "            model,\n",
    "            X_train_vec, train_labels,\n",
    "            X_test_vec, test_labels,\n",
    "            name=name\n",
    "        )\n",
    "    )\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:24:33.211159Z",
     "start_time": "2025-12-01T09:24:23.759088Z"
    }
   },
   "id": "71b837978185a2b0",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1 range=(-6.246, 1.998), tau=-1.361\n",
      "Iter 2 range=(-2.475, -0.247), tau=-1.478\n",
      "Iter 3 range=(-1.692, -1.264), tau=-1.561\n",
      "Iter 4 range=(-1.604, -1.518), tau=-1.562\n",
      "Iter 5 range=(-1.576, -1.549), tau=-1.573\n",
      "Iter 6 range=(-1.576, -1.570), tau=-1.571\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = TbNB(iterative=True)\n",
    "clf.fit(X_train_vec, train_labels)\n",
    "\n",
    "for d in clf.decisions_:\n",
    "    print(\n",
    "            f\"Iter {d.iteration}\",\n",
    "            f\"range=({d.start:.3f}, {d.end:.3f}), tau={d.tau:.3f}\"\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:24:38.025595Z",
     "start_time": "2025-12-01T09:24:33.215920Z"
    }
   },
   "id": "4e86fb8a2870ef22",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Decision(iteration=1, start=np.float64(-6.246217114233314), end=np.float64(1.9975913158401266), tau=np.float64(-1.3609973038194232), x_max_pos=np.float64(1.8655583479911027), x_max_neg=np.float64(-3.7293386646112925), direction='r'),\n Decision(iteration=2, start=np.float64(-2.4749346804325243), end=np.float64(-0.24705597433169246), tau=np.float64(-1.4780760401651851), x_max_pos=np.float64(-0.8514154631738602), x_max_neg=np.float64(-1.904026823814093), direction='r'),\n Decision(iteration=3, start=np.float64(-1.6918429767233643), end=np.float64(-1.26409030310119), tau=np.float64(-1.5612478161079857), x_max_pos=np.float64(-1.3283174312726878), x_max_neg=np.float64(-1.3227510801644913), direction='l'),\n Decision(iteration=4, start=np.float64(-1.6044822827943053), end=np.float64(-1.5180760485661766), tau=np.float64(-1.5624468174941346), x_max_pos=np.float64(-1.536066535772834), x_max_neg=np.float64(-1.5425534902944653), direction='r'),\n Decision(iteration=5, start=np.float64(-1.5758464182368939), end=np.float64(-1.5489718784954212), tau=np.float64(-1.572941062589167), x_max_pos=np.float64(-1.5667537311171564), x_max_neg=np.float64(-1.5634448538516899), direction='l'),\n Decision(iteration=6, start=np.float64(-1.5756177054730203), end=np.float64(-1.5702333718275305), tau=np.float64(-1.5708747489084247), x_max_pos=np.float64(-1.5717478840941799), x_max_neg=np.float64(-1.5748900928182243), direction='r')]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decisions_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:24:38.044163Z",
     "start_time": "2025-12-01T09:24:38.028763Z"
    }
   },
   "id": "2cb7cbfccdcd40fd",
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
