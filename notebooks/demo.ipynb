{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sentiment Analysis  of text documents using TbNB\n",
    "\n",
    "This is an example showing how TbNB can be used to classify documents by sentiment using a Bag of Words approach. This demo uses a binary document-term sparse matrix to encode the features and demonstrates the correct procedure to correctly train and utilize a (iterative) Threshold-Based Naive Bayes model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72374e5ceeb930e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50d73e477b1b2b8a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_dataset' from 'datasets' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mTbNB\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TbNB\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m \n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfeature_extraction\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtext\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CountVectorizer\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'load_dataset' from 'datasets' (unknown location)"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from models.tbnb import TbNB\n",
    "import numpy as np \n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:20:22.346191Z",
     "start_time": "2025-12-01T09:20:19.886430Z"
    }
   },
   "id": "5729d6cf64f730f5",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import data and perform train/test split\n",
    "\n",
    "Here we'll employ a simple sentiment dataset containing various reviews. We split the dataset in training and test data (counting 25k samples each), and according to dependent and independent variables."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edba0c484dcc3ad3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_polarity\")\n",
    "train = dataset[\"train\"].shuffle(seed=42).select(range(100_000))\n",
    "test = dataset[\"test\"]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40593918f0272fd9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train_text = train[\"text\"]\n",
    "y_train = np.array(train[\"label\"])\n",
    "X_test_text = test[\"text\"]\n",
    "y_test = np.array(test[\"label\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:20:22.348987Z",
     "start_time": "2025-12-01T09:20:22.348643Z"
    }
   },
   "id": "e70c7ded544376d2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Text Vectorization\n",
    "\n",
    "We leverage scikit-learn's CountVectorizer in order to remove stopwords and to create a BoW matrix signifying word presence/absence within each document. The vectorizer is fitted on training and data and is used to transform both training and test data. As the output indicates, CountVectorizer's output type defaults to a scipy sparse matrix, a format especially fitting for BoW data, which allows for extremely fast computations. However, TbNB also accepts other formats for X, such as numpy.ndarray or pandas dataframe. These formats are converted internally into sparse matrices. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4c214e7ed1f867"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=False, stop_words=\"english\")\n",
    "X_train = vectorizer.fit_transform(X_train_text)\n",
    "X_test = vectorizer.transform(X_test_text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2c566f48a5d9291",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "type(X_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f6714f0dc0b7cad",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Initialize and train the TbNB Model\n",
    "\n",
    "We instantiate the model with iterative=True, which means calling fit will automatically estimate class priors and employ the iterative optimization algorithm described in Romano, M., Zammarchi, G., & Conversano, C. (2024). The .fit() method returns the fitted model and can be used for predictions using dot notation.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62c9efd0b7b8a79a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = TbNB(iterative=True)\n",
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Predicted labels:\", y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b9f6c5bedf679fc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b3ee7890992eff0e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate Performance and post-hoc analysis\n",
    "\n",
    "We can evaluate the modelâ€™s accuracy and other metrics using standard scikit-learn functions, as well as inspect learned attributed using the TbNB class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bffe10aa96806a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=[\"Negative\", \"Positive\"]))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "299d542fb9e618b5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspect\n",
    " Once the model is trained, one can simply access learned parameters by calling their name using dot notation "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c8d9e1dbebf8055"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"Decision threshold (tau_):\", model.threshold_)\n",
    "print(\"Number of features (words):\", model.n_features_in_)\n",
    "print(\"Review scores (lambda_scores_):\")\n",
    "print(model.lambda_scores_[:10])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87602cf79b2cb9a0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Benchmark\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "491186b95392f588"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "def benchmark_model(name, clf, X_train, X_test, y_train, y_test, variant):\n",
    "    \"\"\"Esegue un benchmark e salva i risultati globali.\"\"\"\n",
    "    \n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    t0 = time.time()\n",
    "    preds = clf.predict(X_test)\n",
    "    pred_time = time.time() - t0\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds, average=\"binary\")\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        \"Vectorizer\": variant,\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1-score\": f1,\n",
    "        \"Train Time (s)\": train_time,\n",
    "        \"Predict Time (s)\": pred_time\n",
    "    })\n",
    "\n",
    "\n",
    "vectorizers = {\n",
    "    \"Simple\": CountVectorizer(binary=False, stop_words=\"english\"),\n",
    "    \"N_grams\": CountVectorizer(binary=False, stop_words=\"english\", ngram_range=(1,2))\n",
    "}\n",
    "\n",
    "for variant, vectorizer in vectorizers.items():\n",
    "\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"  Running Vectorizer: {variant}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    X_train_vec = vectorizer.fit_transform(X_train_text)\n",
    "    X_test_vec = vectorizer.transform(X_test_text)\n",
    "\n",
    "    benchmark_model(\n",
    "        f\"TbNB\",\n",
    "        TbNB(iterative=False),\n",
    "        X_train_vec,\n",
    "        X_test_vec,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        variant\n",
    "    )\n",
    "    \n",
    "    benchmark_model(\n",
    "        f\"iTbNB\",\n",
    "        TbNB(iterative=True),\n",
    "        X_train_vec,\n",
    "        X_test_vec,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        variant\n",
    "    )\n",
    "\n",
    "    benchmark_model(\n",
    "        \"BernoulliNB\",\n",
    "        BernoulliNB(),\n",
    "        X_train_vec,\n",
    "        X_test_vec,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        variant\n",
    "    )\n",
    "\n",
    "    benchmark_model(\n",
    "        \"MultinomialNB\",\n",
    "        MultinomialNB(),\n",
    "        X_train_vec,\n",
    "        X_test_vec,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        variant\n",
    "    )\n",
    "\n",
    "    benchmark_model(\n",
    "        \"ComplementNB\",\n",
    "        ComplementNB(),\n",
    "        X_train_vec,\n",
    "        X_test_vec,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        variant\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results).sort_values(by=[\"Vectorizer\", \"Accuracy\"], ascending=[True, False])\n",
    "print(\"\\n\\n=== RISULTATI FINALI ===\")\n",
    "print(df.to_string(index=False))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cdfeba2b5748282",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "42f6250542bb3978"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a25e73d8511a672b"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d357f908cbc5eb7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "from preprocessing.nltk_pipeline import TextPreprocessor\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "\n",
    "results = []\n",
    "\n",
    "def benchmark_model(name, pipeline, X_train, X_test, y_train, y_test, variant):\n",
    "    \"\"\"Esegue un benchmark e salva i risultati globali.\"\"\"\n",
    "\n",
    "    # Train\n",
    "    t0 = time.time()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    # Predict\n",
    "    t0 = time.time()\n",
    "    preds = pipeline.predict(X_test)\n",
    "    pred_time = time.time() - t0\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds, average=\"binary\")\n",
    "\n",
    "    results.append({\n",
    "        \"Vectorizer\": variant,\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1-score\": f1,\n",
    "        \"Train Time (s)\": train_time,\n",
    "        \"Predict Time (s)\": pred_time\n",
    "    })\n",
    "\n",
    "vectorizers = {\n",
    "    \"Simple\": CountVectorizer(binary=False),\n",
    "    \"N_grams\": CountVectorizer(binary=False, ngram_range=(1,2)),\n",
    "}\n",
    "\n",
    "\n",
    "preprocessor = TextPreprocessor(\n",
    "    language=\"english\",\n",
    "    remove_html=False,\n",
    "    remove_urls=False,\n",
    "    lower=True,\n",
    "    expand_contr=True,\n",
    "    remove_punct=True,\n",
    "    remove_sw=True,\n",
    "    stem=True\n",
    ")\n",
    "\n",
    "X_train_clean = preprocessor.fit_transform(X_train_text)\n",
    "X_test_clean  = preprocessor.transform(X_test_text)\n",
    "\n",
    "\n",
    "for variant, vectorizer in vectorizers.items():\n",
    "\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"  Running Vectorizer: {variant}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    X_train_vec = vectorizer.fit_transform(X_train_clean)\n",
    "    X_test_vec = vectorizer.transform(X_test_clean)\n",
    "\n",
    "    benchmark_model(\"TbNB\", TbNB(iterative=False),\n",
    "                    X_train_vec, X_test_vec, y_train, y_test, variant)\n",
    "\n",
    "    benchmark_model(\"iTbNB\", TbNB(iterative=True),\n",
    "                    X_train_vec, X_test_vec, y_train, y_test, variant)\n",
    "\n",
    "    benchmark_model(\"BernoulliNB\", BernoulliNB(),\n",
    "                    X_train_vec, X_test_vec, y_train, y_test, variant)\n",
    "\n",
    "    benchmark_model(\"MultinomialNB\", MultinomialNB(),\n",
    "                    X_train_vec, X_test_vec, y_train, y_test, variant)\n",
    "\n",
    "    benchmark_model(\"ComplementNB\", ComplementNB(),\n",
    "                    X_train_vec, X_test_vec, y_train, y_test, variant)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results).sort_values(by=[\"Vectorizer\", \"Accuracy\"], ascending=[True, False])\n",
    "print(\"\\n\\n=== RISULTATI FINALI ===\")\n",
    "print(df.to_string(index=False))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5ddecb6c6b1c8a7",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
